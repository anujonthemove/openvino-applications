{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This pipline is mainly for the following OpenVINO models:\n",
    "\n",
    "* person-detection-0200\n",
    "* person-detection-0201\n",
    "* person-detection-0202\n",
    "* person-detection-0203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import openvino as ov\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoPlayer:\n",
    "\n",
    "    def __init__(self, source, fps=None):\n",
    "\n",
    "        self.cv2 = cv2  # This is done to access the package in class methods\n",
    "        self.__cap = cv2.VideoCapture(source)\n",
    "        if not self.__cap.isOpened():\n",
    "            raise RuntimeError(\n",
    "                f\"Cannot open {'camera' if isinstance(source, int) else ''} {source}\"\n",
    "            )\n",
    "        # fps of input file\n",
    "        self.__input_fps = self.__cap.get(cv2.CAP_PROP_FPS)\n",
    "        if self.__input_fps <= 0:\n",
    "            self.__input_fps = 60\n",
    "        # target fps given by user\n",
    "        self.__output_fps = fps if fps is not None else self.__input_fps\n",
    "        self.__size = None\n",
    "        \n",
    "        # first frame\n",
    "        _, self.__frame = self.__cap.read()\n",
    "        self.__lock = threading.Lock()\n",
    "        self.__thread = None\n",
    "        self.__stop = False\n",
    "\n",
    "    def start(self):\n",
    "        self.__stop = False\n",
    "        self.__thread = threading.Thread(target=self.__run, daemon=True)\n",
    "        self.__thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        self.__stop = True\n",
    "        if self.__thread is not None:\n",
    "            self.__thread.join()\n",
    "        self.__cap.release()\n",
    "\n",
    "    def __run(self):\n",
    "        prev_time = 0\n",
    "        while not self.__stop:\n",
    "            t1 = time.time()\n",
    "            ret, frame = self.__cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # fulfill target fps\n",
    "            if 1 / self.__output_fps < time.time() - prev_time:\n",
    "                prev_time = time.time()\n",
    "                # replace by current frame\n",
    "                with self.__lock:\n",
    "                    self.__frame = frame\n",
    "\n",
    "            t2 = time.time()\n",
    "            # time to wait [s] to fulfill input fps\n",
    "            wait_time = 1 / self.__input_fps - (t2 - t1)\n",
    "            # wait until\n",
    "            time.sleep(max(0, wait_time))\n",
    "\n",
    "        self.__frame = None\n",
    "\n",
    "    def next(self):\n",
    "        import cv2\n",
    "\n",
    "        with self.__lock:\n",
    "            if self.__frame is None:\n",
    "                return None\n",
    "            # need to copy frame, because can be cached and reused if fps is low\n",
    "            frame = self.__frame.copy()\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionPipeline:\n",
    "    def __init__(self, model_path, device='CPU'):\n",
    "        self.core = ov.Core()\n",
    "        self.model_path = model_path\n",
    "        self.device = device\n",
    "        self.model = self.load_model()\n",
    "        self.compiled_model = self.core.compile_model(model=self.model, device_name=self.device)\n",
    "        self.input_layer_ir = self.model.input(0)\n",
    "        self.shape = self.get_shape()\n",
    "\n",
    "    def load_model(self):\n",
    "        model = self.core.read_model(model=self.model_path)\n",
    "        return model\n",
    "\n",
    "    def get_shape(self):\n",
    "        N, C, H, W = self.input_layer_ir.shape\n",
    "        return (H, W)\n",
    "        \n",
    "    def preprocess(self, image):\n",
    "        resized_image = cv2.resize(image, self.shape)\n",
    "        resized_image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_BGR2RGB)\n",
    "        resized_image = resized_image.transpose((2, 0, 1))\n",
    "        resized_image = np.expand_dims(resized_image, axis=0).astype(np.float32)\n",
    "        return resized_image\n",
    "\n",
    "    def postprocess(self, result, image, fps):\n",
    "\n",
    "        detections = result.reshape(-1, 7)\n",
    "        for i, detection in enumerate(detections):\n",
    "            _, image_id, confidence, xmin, ymin, xmax, ymax = detection\n",
    "            if confidence > 0.5:\n",
    "                xmin = int(max((xmin * image.shape[1]), 10))\n",
    "                ymin = int(max((ymin * image.shape[0]), 10))\n",
    "                xmax = int(min((xmax * image.shape[1]), image.shape[1] - 10))\n",
    "                ymax = int(min((ymax * image.shape[0]), image.shape[0] - 10))\n",
    "                cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                cv2.putText(image, str(round(fps, 2)) + \" fps\", (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 3) \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sync(source, required_fps):\n",
    "    \n",
    "    frame_number = 0\n",
    "    required_fps = 30\n",
    "    player = None\n",
    "    title = \"Output\"\n",
    "\n",
    "    infer_request = obj.compiled_model.create_infer_request()\n",
    "\n",
    "    try:\n",
    "        # Create a video player\n",
    "        player = VideoPlayer(source, fps=required_fps)\n",
    "        # Start capturing\n",
    "        start_time = time.time()\n",
    "        player.start()\n",
    "        \n",
    "        cv2.namedWindow(title, cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "        \n",
    "        while True:\n",
    "            frame = player.next()\n",
    "            if frame is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "            \n",
    "            resized_frame = obj.preprocess(frame)\n",
    "            infer_request.set_tensor(obj.input_layer_ir, ov.Tensor(resized_frame))\n",
    "            infer_request.infer()\n",
    "            res = infer_request.get_output_tensor(0).data\n",
    "            stop_time = time.time()\n",
    "            total_time = stop_time - start_time\n",
    "            frame_number = frame_number + 1\n",
    "            sync_fps = frame_number / total_time\n",
    "\n",
    "            frame = obj.postprocess(res, frame, sync_fps)\n",
    "\n",
    "            \n",
    "            cv2.putText(frame, str(round(sync_fps, 2)) + \" fps\", (5, 100), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 0), 1)\n",
    "            cv2.putText(frame, str(frame_number) + \" frame\", (5, 150), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 0), 1)\n",
    "            \n",
    "            cv2.imshow(title, frame)\n",
    "            key = cv2.waitKey(1)\n",
    "            # escape = 27\n",
    "            if key == 27:\n",
    "                break\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    # Any different error\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()\n",
    "        if player is not None:\n",
    "            player.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_async(source, required_async_fps):\n",
    "    \n",
    "    frame_number = 0\n",
    "    \n",
    "    current_request = obj.compiled_model.create_infer_request()\n",
    "    next_request = obj.compiled_model.create_infer_request()\n",
    "\n",
    "    required_async_fps = 30\n",
    "    player = None\n",
    "    title = \"Output\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Create a video player\n",
    "        player = VideoPlayer(source, fps=required_async_fps)\n",
    "        # Start capturing\n",
    "        start_time = time.time()\n",
    "        player.start()\n",
    "        frame = player.next()\n",
    "        resized_frame = obj.preprocess(frame)\n",
    "        current_request.set_tensor(obj.input_layer_ir, ov.Tensor(resized_frame))\n",
    "        current_request.start_async()\n",
    "        cv2.namedWindow(title, cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "        \n",
    "        while True:\n",
    "            next_frame = player.next()\n",
    "            if next_frame is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "            \n",
    "            resized_frame = obj.preprocess(next_frame)\n",
    "\n",
    "            next_request.set_tensor(obj.input_layer_ir, ov.Tensor(resized_frame))\n",
    "            next_request.start_async()\n",
    "\n",
    "            current_request.wait()\n",
    "\n",
    "            res = current_request.get_output_tensor(0).data\n",
    "            stop_time = time.time()\n",
    "            total_time = stop_time - start_time\n",
    "            frame_number = frame_number + 1\n",
    "            async_fps = frame_number / total_time\n",
    "\n",
    "            frame = obj.postprocess(res, frame, async_fps)\n",
    "\n",
    "            \n",
    "            cv2.putText(frame, str(round(async_fps, 2)) + \" fps\", (5, 100), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 0), 1)\n",
    "            cv2.putText(frame, str(frame_number) + \" frame\", (5, 150), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 0), 1)\n",
    "            \n",
    "            cv2.imshow(title, frame)\n",
    "            key = cv2.waitKey(1)\n",
    "            # escape = 27\n",
    "            if key == 27:\n",
    "                break\n",
    "            \n",
    "            frame = next_frame\n",
    "            current_request, next_request = next_request, current_request\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    # Any different error\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()\n",
    "        if player is not None:\n",
    "            player.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_path = \"/home/acer/workspace/intel_models/intel/person-vehicle-bike-detection-2000/FP32/person-vehicle-bike-detection-2000.xml\"\n",
    "    obj = DetectionPipeline(model_path=model_path)\n",
    "    run_sync(source=2, required_fps=30)\n",
    "    run_async(source=2, required_async_fps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
