{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This pipline works mainly for the following OpenVINO models:\n",
    "\n",
    "* person-detection-0200\n",
    "* person-detection-0201\n",
    "* person-detection-0202\n",
    "* person-detection-0203\n",
    "* person-vehicle-bike-detection-2000\n",
    "\n",
    "For all of these models, the net outputs blob with shape: 1, 1, 200, 7 in the format 1, 1, N, 7, where N is the number of detected bounding boxes. Each detection has the format [image_id, label, conf, x_min, y_min, x_max, y_max], where:\n",
    "\n",
    "* image_id - ID of the image in the batch\n",
    "* label - predicted class ID (0 - person)\n",
    "* conf - confidence for the predicted class\n",
    "* (x_min, y_min) - coordinates of the top left bounding box corner\n",
    "* (x_max, y_max) - coordinates of the bottom right bounding box corner\n",
    "\n",
    "At the moment, the postprocessing function in the code has been only written for this particular output shape tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory and add the parent directory to the Python path\n",
    "current_working_directory = os.getcwd()\n",
    "sys.path.append(os.path.join(current_working_directory, \"..\"))\n",
    "\n",
    "from helpers.helpers import (\n",
    "    VideoPlayer,\n",
    "    are_polygons_intersecting,\n",
    "    capture_frame_for_ROI,\n",
    "    create_ROI,\n",
    "    is_point_inside_polygon,\n",
    "    compute_polygon_intersection\n",
    ")\n",
    "\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "import threading\n",
    "import openvino as ov\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_COLOR = (0, 255, 255)\n",
    "ROI_FILL_COLOR = (255, 0, 255)\n",
    "BOX_COLOR = (0, 255, 0)\n",
    "BOX_INTRUSION_COLOR = (0, 0, 255)\n",
    "BOX_FILL_COLOR = (255, 255, 0)\n",
    "INFO_TEXT_COLOR = (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonIntrusionDetection:\n",
    "    def __init__(self, model_path, roi=None, device='CPU'):\n",
    "        \n",
    "        assert roi is not None, \"ROI must be set.\"\n",
    "\n",
    "        self.core = ov.Core()\n",
    "        self.model = self.load_model(model_path)\n",
    "        self.device = device\n",
    "        self.compiled_model = self.core.compile_model(model=self.model, device_name=self.device)\n",
    "        self.input_layer_ir = self.model.input(0)\n",
    "        self.shape = self.get_shape()\n",
    "        self.roi = roi\n",
    "        self.person_detection_confidence_threshold = 0.5\n",
    "        self.intersection_threshold = 0.1\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        assert os.path.exists(model_path), f\"Model file not found at {model_path}\"\n",
    "        return self.core.read_model(model=model_path)\n",
    "        \n",
    "    def get_shape(self):\n",
    "        N, C, H, W = self.input_layer_ir.shape\n",
    "        return H, W\n",
    "\n",
    "    def preprocess_frame(self, frame):\n",
    "        resized_frame = cv2.resize(frame, self.shape)\n",
    "        resized_frame = cv2.cvtColor(np.array(resized_frame), cv2.COLOR_BGR2RGB)\n",
    "        resized_frame = resized_frame.transpose((2, 0, 1))\n",
    "        resized_frame = np.expand_dims(resized_frame, axis=0).astype(np.float32)\n",
    "        return resized_frame\n",
    "\n",
    "    def postprocess_bboxes(self, frame, result):\n",
    "        bboxes = []\n",
    "        detections = result.reshape(-1, 7)\n",
    "        for i, detection in enumerate(detections):\n",
    "            _, frame_id, confidence, xmin, ymin, xmax, ymax = detection\n",
    "\n",
    "            if confidence > self.person_detection_confidence_threshold:\n",
    "                xmin = int(max((xmin * frame.shape[1]), 10))\n",
    "                ymin = int(max((ymin * frame.shape[0]), 10))\n",
    "                xmax = int(min((xmax * frame.shape[1]), frame.shape[1] - 10))\n",
    "                ymax = int(min((ymax * frame.shape[0]), frame.shape[0] - 10))\n",
    "\n",
    "                bbox = [(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)]\n",
    "                bboxes.append(np.array(bbox, dtype=np.int32))\n",
    "\n",
    "                # Draw bbox around detected people\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), BOX_COLOR, 2)\n",
    "\n",
    "        return frame, bboxes\n",
    "\n",
    "    def run_inference(self, resized_frame, infer_request):\n",
    "        infer_request.set_tensor(self.input_layer_ir, ov.Tensor(resized_frame))\n",
    "        infer_request.infer()\n",
    "        result = infer_request.get_output_tensor(0).data\n",
    "        return result\n",
    "\n",
    "    def check_intrusion(self, frame, bboxes):\n",
    "\n",
    "        intrusions = []\n",
    "        for bbox in bboxes:\n",
    "            # 1. use this to control when to call out intrusion based on how much the bbox \n",
    "            # overlapps with the roi\n",
    "            # intrusion = are_polygons_intersecting(self.roi, bbox, intersection_threshold=self.intersection_threshold)\n",
    "\n",
    "            # 2. use this when you want to check if a standing person's bbox base intersects\n",
    "            # the ROI and both the bottom left and right points are falling inside the polygon\n",
    "            intrusion = are_polygons_intersecting(self.roi, bbox, intersection_threshold=self.intersection_threshold) \\\n",
    "                and is_point_inside_polygon(self.roi, bbox[2]) \\\n",
    "                    and is_point_inside_polygon(self.roi, bbox[3])\n",
    "            \n",
    "            intrusions.append(intrusion)\n",
    "        return intrusions\n",
    "        \n",
    "\n",
    "    def annotate_frame(self, frame, sync_fps, num_intrusions):\n",
    "        cv2.putText(frame, f\"{round(sync_fps, 2)} FPS\", (5, 30), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Intrusion(s): {num_intrusions}\", (5, 60), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 255), 2)\n",
    "        cv2.polylines(frame, [np.array(self.roi, np.int32)], True, ROI_COLOR, thickness = 2)\n",
    "        return frame\n",
    "\n",
    "    def get_num_intrusions(self, intrusions):\n",
    "        return np.sum(intrusions)\n",
    "\n",
    "    def run_sync(self, source=0, required_fps=30, title=\"Intrusion Detection\", debug=True):\n",
    "        frame_number = 0\n",
    "        player = None\n",
    "\n",
    "        # create inference request\n",
    "        infer_request = self.compiled_model.create_infer_request()\n",
    "\n",
    "        try:\n",
    "            # Create a video player\n",
    "            player = VideoPlayer(source, fps=required_fps)\n",
    "            # Start capturing\n",
    "            start_time = time.time()\n",
    "            player.start()\n",
    "\n",
    "            while True:\n",
    "                frame = player.next()\n",
    "                \n",
    "                if frame is None:\n",
    "                    print(\"Source ended\")\n",
    "                    break\n",
    "                \n",
    "                resized_frame = self.preprocess_frame(frame)\n",
    "\n",
    "                result = self.run_inference(resized_frame, infer_request)\n",
    "\n",
    "                stop_time = time.time()\n",
    "                total_time = stop_time - start_time\n",
    "                frame_number += 1\n",
    "                sync_fps = frame_number / total_time\n",
    "                frame, bboxes = self.postprocess_bboxes(frame, result)\n",
    "                intrusions = self.check_intrusion(frame, bboxes)\n",
    "                num_intrusions = self.get_num_intrusions(intrusions)\n",
    "                frame = self.annotate_frame(frame, sync_fps, num_intrusions)\n",
    "                cv2.namedWindow(title, cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "                cv2.imshow(title, frame)\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                key = cv2.waitKey(1)\n",
    "                # escape = 27\n",
    "                if key == 27:\n",
    "                    break\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Processing interrupted by user.\")\n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "            if player is not None:\n",
    "                player.stop()\n",
    "\n",
    "\n",
    "    def run_async(self, source, required_async_fps, title=\"Intrusion Detection\", debug=True):\n",
    "        frame_number = 0\n",
    "        current_request = self.compiled_model.create_infer_request()\n",
    "        next_request = self.compiled_model.create_infer_request()\n",
    "        player = None\n",
    "\n",
    "        try:\n",
    "            # Create a video player\n",
    "            player = VideoPlayer(source, fps=required_async_fps)\n",
    "            # Start capturing\n",
    "            start_time = time.time()\n",
    "            player.start()\n",
    "            frame = player.next()\n",
    "            resized_frame = self.preprocess_frame(frame)\n",
    "            current_request.set_tensor(self.input_layer_ir, ov.Tensor(resized_frame))\n",
    "            current_request.start_async()\n",
    "            \n",
    "            while True:\n",
    "                next_frame = player.next()\n",
    "                if next_frame is None:\n",
    "                    print(\"Source ended\")\n",
    "                    break\n",
    "                \n",
    "                resized_frame = self.preprocess_frame(next_frame)\n",
    "\n",
    "                next_request.set_tensor(self.input_layer_ir, ov.Tensor(resized_frame))\n",
    "                next_request.start_async()\n",
    "                current_request.wait()\n",
    "\n",
    "                result = current_request.get_output_tensor(0).data\n",
    "                \n",
    "                stop_time = time.time()\n",
    "                total_time = stop_time - start_time\n",
    "                frame_number = frame_number + 1\n",
    "                async_fps = frame_number / total_time\n",
    "                frame, bboxes = self.postprocess_bboxes(frame, result)\n",
    "                intrusions = self.check_intrusion(frame, bboxes)\n",
    "                num_intrusions = self.get_num_intrusions(intrusions)\n",
    "                frame = self.annotate_frame(frame, async_fps, num_intrusions)\n",
    "                \n",
    "                cv2.namedWindow(title, cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "                cv2.imshow(title, frame)\n",
    "                \n",
    "                \n",
    "                key = cv2.waitKey(1)\n",
    "                # escape = 27\n",
    "                if key == 27:\n",
    "                    break\n",
    "                \n",
    "                frame = next_frame\n",
    "                current_request, next_request = next_request, current_request\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupted\")\n",
    "        # Any different error\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "            if player is not None:\n",
    "                player.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_person_detection(source, model_path, roi, required_fps=30, debug=True, with_async=True):\n",
    "    obj = PersonIntrusionDetection(model_path=model_path, roi=roi)\n",
    "    if with_async:\n",
    "        print(\"Running in Async Mode\")\n",
    "        obj.run_async(source=source, required_async_fps=required_fps, debug=debug)\n",
    "    else:\n",
    "        print(\"Running in Sync Mode\")\n",
    "        obj.run_sync(source=source, required_fps=required_fps, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    source = 2\n",
    "    model_path = \"/home/acer/workspace/intel_models/intel/person-vehicle-bike-detection-2000/FP16/person-vehicle-bike-detection-2000.xml\"\n",
    "\n",
    "    try:\n",
    "        frame = capture_frame_for_ROI(source=source)\n",
    "        if frame is not None:\n",
    "            roi = create_ROI(frame)\n",
    "            run_person_detection(source, model_path, roi, required_fps=30, debug=True, with_async=True)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Use left click to draw polygon, right click to release and finish\n",
      "\n",
      "Adding point #0 with position (102, 100)\n",
      "Adding point #1 with position (494, 100)\n",
      "Adding point #2 with position (495, 477)\n",
      "Adding point #3 with position (96, 478)\n",
      "Polygon Points: [(102, 100), (494, 100), (495, 477), (96, 478)]\n",
      "Running in Async Mode\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
